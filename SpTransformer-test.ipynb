{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhqt5zvpck/fFOSh2ArLkz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Good-lei/SpTransformer-Colab/blob/main/SpTransformer-test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 克隆仓库"
      ],
      "metadata": {
        "id": "E30LzJdP6UJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Good-lei/SpTransformer-Colab.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CaDAWSo_3cGq",
        "outputId": "488ed6cd-7786-4414-8b2a-8373773d84f7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SpTransformer-Colab'...\n",
            "remote: Enumerating objects: 30, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 30 (delta 2), reused 0 (delta 0), pack-reused 24 (from 1)\u001b[K\n",
            "Receiving objects: 100% (30/30), 43.19 MiB | 36.85 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyfaidx pyvcf3 pyensembl sinkhorn_transformer\n",
        "\n",
        "# 1️⃣ 先降级 NumPy，防止与 pandas / pyarrow / torch 不兼容\n",
        "!pip install numpy==1.26.4 --force-reinstall -q\n",
        "\n",
        "# 3️⃣ 安装核心依赖（数据、模型、结构）\n",
        "!pip install pandas pyarrow tqdm scikit-learn einops biopython -q\n",
        "\n",
        "# 4️⃣ 安装 SpliceTransformer 特定依赖\n",
        "!pip install axial-positional-embedding rpy2 -q\n",
        "\n",
        "## 警告统统不用管"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "8OfNt9peDEns",
        "outputId": "665109ae-24ad-483d-d895-3200357bb888"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyfaidx\n",
            "  Downloading pyfaidx-0.9.0.3-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pyvcf3\n",
            "  Downloading pyvcf3-1.0.4-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting pyensembl\n",
            "  Downloading pyensembl-2.3.13-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting sinkhorn_transformer\n",
            "  Downloading sinkhorn_transformer-0.11.4-py3-none-any.whl.metadata (734 bytes)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from pyfaidx) (25.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from pyvcf3) (75.2.0)\n",
            "Collecting typechecks<1.0.0,>=0.0.2 (from pyensembl)\n",
            "  Downloading typechecks-0.1.0.tar.gz (3.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting datacache<2.0.0,>=1.4.0 (from pyensembl)\n",
            "  Downloading datacache-1.4.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting memoized-property>=1.0.2 (from pyensembl)\n",
            "  Downloading memoized-property-1.0.3.tar.gz (5.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tinytimer<1.0.0,>=0.0.0 (from pyensembl)\n",
            "  Downloading tinytimer-0.0.0.tar.gz (2.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gtfparse<3.0.0,>=2.5.0 (from pyensembl)\n",
            "  Downloading gtfparse-2.5.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting serializable<1.0.0,>=0.2.1 (from pyensembl)\n",
            "  Downloading serializable-0.4.1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pylint<3.0.0,>=2.17.2 (from pyensembl)\n",
            "  Downloading pylint-2.17.7-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting axial-positional-embedding>=0.1.0 (from sinkhorn_transformer)\n",
            "  Downloading axial_positional_embedding-0.3.12-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting local-attention (from sinkhorn_transformer)\n",
            "  Downloading local_attention-1.11.2-py3-none-any.whl.metadata (929 bytes)\n",
            "Collecting product-key-memory (from sinkhorn_transformer)\n",
            "  Downloading product_key_memory-0.3.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from sinkhorn_transformer) (2.8.0+cu126)\n",
            "Requirement already satisfied: einops>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from axial-positional-embedding>=0.1.0->sinkhorn_transformer) (0.8.1)\n",
            "Requirement already satisfied: pandas>=0.15.2 in /usr/local/lib/python3.12/dist-packages (from datacache<2.0.0,>=1.4.0->pyensembl) (2.2.2)\n",
            "Collecting appdirs>=1.4.0 (from datacache<2.0.0,>=1.4.0->pyensembl)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting progressbar33>=2.4 (from datacache<2.0.0,>=1.4.0->pyensembl)\n",
            "  Downloading progressbar33-2.4.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from datacache<2.0.0,>=1.4.0->pyensembl) (2.32.4)\n",
            "Collecting mock (from datacache<2.0.0,>=1.4.0->pyensembl)\n",
            "  Downloading mock-5.2.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting polars<0.21.0,>=0.20.2 (from gtfparse<3.0.0,>=2.5.0->pyensembl)\n",
            "  Downloading polars-0.20.31-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting pyarrow<14.1.0,>=14.0.2 (from gtfparse<3.0.0,>=2.5.0->pyensembl)\n",
            "  Downloading pyarrow-14.0.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from pylint<3.0.0,>=2.17.2->pyensembl) (4.5.0)\n",
            "Collecting astroid<=2.17.0-dev0,>=2.15.8 (from pylint<3.0.0,>=2.17.2->pyensembl)\n",
            "  Downloading astroid-2.15.8-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting isort<6,>=4.2.5 (from pylint<3.0.0,>=2.17.2->pyensembl)\n",
            "  Downloading isort-5.13.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mccabe<0.8,>=0.6 (from pylint<3.0.0,>=2.17.2->pyensembl)\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: tomlkit>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from pylint<3.0.0,>=2.17.2->pyensembl) (0.13.3)\n",
            "Requirement already satisfied: dill>=0.3.6 in /usr/local/lib/python3.12/dist-packages (from pylint<3.0.0,>=2.17.2->pyensembl) (0.3.8)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.12/dist-packages (from serializable<1.0.0,>=0.2.1->pyensembl) (3.20.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->sinkhorn_transformer) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->sinkhorn_transformer) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->sinkhorn_transformer) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->sinkhorn_transformer) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->sinkhorn_transformer) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->sinkhorn_transformer) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->sinkhorn_transformer) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->sinkhorn_transformer) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->sinkhorn_transformer) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->sinkhorn_transformer) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->sinkhorn_transformer) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->sinkhorn_transformer) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->sinkhorn_transformer) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->sinkhorn_transformer) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->sinkhorn_transformer) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->sinkhorn_transformer) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->sinkhorn_transformer) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->sinkhorn_transformer) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->sinkhorn_transformer) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->sinkhorn_transformer) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->sinkhorn_transformer) (3.4.0)\n",
            "Collecting hyper-connections>=0.1.8 (from local-attention->sinkhorn_transformer)\n",
            "  Downloading hyper_connections-0.2.1-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting colt5-attention>=0.10.14 (from product-key-memory->sinkhorn_transformer)\n",
            "  Downloading CoLT5_attention-0.11.1-py3-none-any.whl.metadata (737 bytes)\n",
            "Collecting lazy-object-proxy>=1.4.0 (from astroid<=2.17.0-dev0,>=2.15.8->pylint<3.0.0,>=2.17.2->pyensembl)\n",
            "  Downloading lazy_object_proxy-1.12.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting wrapt<2,>=1.14 (from astroid<=2.17.0-dev0,>=2.15.8->pylint<3.0.0,>=2.17.2->pyensembl)\n",
            "  Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.15.2->datacache<2.0.0,>=1.4.0->pyensembl) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.15.2->datacache<2.0.0,>=1.4.0->pyensembl) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.15.2->datacache<2.0.0,>=1.4.0->pyensembl) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.15.2->datacache<2.0.0,>=1.4.0->pyensembl) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.1->datacache<2.0.0,>=1.4.0->pyensembl) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.1->datacache<2.0.0,>=1.4.0->pyensembl) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.1->datacache<2.0.0,>=1.4.0->pyensembl) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.1->datacache<2.0.0,>=1.4.0->pyensembl) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->sinkhorn_transformer) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->sinkhorn_transformer) (3.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=0.15.2->datacache<2.0.0,>=1.4.0->pyensembl) (1.17.0)\n",
            "Downloading pyfaidx-0.9.0.3-py3-none-any.whl (29 kB)\n",
            "Downloading pyvcf3-1.0.4-py3-none-any.whl (988 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m988.6/988.6 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyensembl-2.3.13-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.0/56.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sinkhorn_transformer-0.11.4-py3-none-any.whl (14 kB)\n",
            "Downloading axial_positional_embedding-0.3.12-py3-none-any.whl (6.7 kB)\n",
            "Downloading datacache-1.4.1-py3-none-any.whl (20 kB)\n",
            "Downloading gtfparse-2.5.0-py3-none-any.whl (15 kB)\n",
            "Downloading pylint-2.17.7-py3-none-any.whl (537 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m537.2/537.2 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading serializable-0.4.1-py3-none-any.whl (12 kB)\n",
            "Downloading local_attention-1.11.2-py3-none-any.whl (9.5 kB)\n",
            "Downloading product_key_memory-0.3.0-py3-none-any.whl (8.3 kB)\n",
            "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading astroid-2.15.8-py3-none-any.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.3/278.3 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading CoLT5_attention-0.11.1-py3-none-any.whl (18 kB)\n",
            "Downloading hyper_connections-0.2.1-py3-none-any.whl (16 kB)\n",
            "Downloading isort-5.13.2-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.3/92.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Downloading polars-0.20.31-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-14.0.2-cp312-cp312-manylinux_2_28_x86_64.whl (38.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mock-5.2.0-py3-none-any.whl (31 kB)\n",
            "Downloading lazy_object_proxy-1.12.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: memoized-property, tinytimer, typechecks, progressbar33\n",
            "  Building wheel for memoized-property (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for memoized-property: filename=memoized_property-1.0.3-py2.py3-none-any.whl size=4186 sha256=9b6cf403aa2a1727175e80bf1a4c09794f6f96d84d99c47478d10bdfd47a605f\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/a1/bd/6052f3ea93ccfa6eeeb00db24fcd3d8b2fa1623a4f6b0dadca\n",
            "  Building wheel for tinytimer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinytimer: filename=tinytimer-0.0.0-py3-none-any.whl size=1874 sha256=a675bc9b8ca9228cdb09d41862cd738791ab8fc015aafdaa75c862e5bbce9bd7\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/16/b9/ed626b157e7f45893fbe973d8003eabbc14f05db92555be0b8\n",
            "  Building wheel for typechecks (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typechecks: filename=typechecks-0.1.0-py3-none-any.whl size=2752 sha256=8c3b6a9a5f4213e31a5544f0b78ff23cc718eaf4d9dd95caa651e9962fce2638\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/fb/17/c339a76041556c9cf0ab9a76acaaaf119ec8019357d6d601b7\n",
            "  Building wheel for progressbar33 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progressbar33: filename=progressbar33-2.4-py3-none-any.whl size=12142 sha256=9726d096ff36ac89e9255d7efd8fad9435872eb76225e51898c44925ef874b5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/09/ed/4e279d221fcf579bf137464a1f2f92adcbbca797db67996156\n",
            "Successfully built memoized-property tinytimer typechecks progressbar33\n",
            "Installing collected packages: typechecks, tinytimer, progressbar33, memoized-property, appdirs, wrapt, serializable, pyvcf3, pyfaidx, pyarrow, polars, mock, mccabe, lazy-object-proxy, isort, gtfparse, astroid, pylint, datacache, pyensembl, hyper-connections, axial-positional-embedding, local-attention, colt5-attention, product-key-memory, sinkhorn_transformer\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 2.0.0\n",
            "    Uninstalling wrapt-2.0.0:\n",
            "      Successfully uninstalled wrapt-2.0.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: polars\n",
            "    Found existing installation: polars 1.25.2\n",
            "    Uninstalling polars-1.25.2:\n",
            "      Successfully uninstalled polars-1.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-polars-cu12 25.6.0 requires polars<1.29,>=1.25, but you have polars 0.20.31 which is incompatible.\n",
            "bigframes 2.28.0 requires pyarrow>=15.0.2, but you have pyarrow 14.0.2 which is incompatible.\n",
            "datasets 4.0.0 requires pyarrow>=15.0.0, but you have pyarrow 14.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed appdirs-1.4.4 astroid-2.15.8 axial-positional-embedding-0.3.12 colt5-attention-0.11.1 datacache-1.4.1 gtfparse-2.5.0 hyper-connections-0.2.1 isort-5.13.2 lazy-object-proxy-1.12.0 local-attention-1.11.2 mccabe-0.7.0 memoized-property-1.0.3 mock-5.2.0 polars-0.20.31 product-key-memory-0.3.0 progressbar33-2.4 pyarrow-14.0.2 pyensembl-2.3.13 pyfaidx-0.9.0.3 pylint-2.17.7 pyvcf3-1.0.4 serializable-0.4.1 sinkhorn_transformer-0.11.4 tinytimer-0.0.0 typechecks-0.1.0 wrapt-1.17.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyarrow"
                ]
              },
              "id": "cedfcda2df1545aba85e52c4cf2951ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "bigframes 2.28.0 requires pyarrow>=15.0.2, but you have pyarrow 14.0.2 which is incompatible.\n",
            "datasets 4.0.0 requires pyarrow>=15.0.0, but you have pyarrow 14.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 下载权重"
      ],
      "metadata": {
        "id": "KeLxut0A6c8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir /content/SpTransformer-Colab/model/weights\n",
        "%cd /content/SpTransformer-Colab/model/weights\n",
        "!pip install -q gdown\n",
        "!gdown --id 1d8n4vHDSbXqpPc_JFEswLomSUDBgHvno -O SpTransformer_pytorch.ckpt\n",
        "%cd /content/SpTransformer-Colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QtOdN4T3cJi",
        "outputId": "fcd469b5-f380-40a0-9b07-6e744c70a060",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SpTransformer-Colab/model/weights\n",
            "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1d8n4vHDSbXqpPc_JFEswLomSUDBgHvno\n",
            "From (redirected): https://drive.google.com/uc?id=1d8n4vHDSbXqpPc_JFEswLomSUDBgHvno&confirm=t&uuid=f1d4168a-e6cf-4056-bd87-2abeff0ebee6\n",
            "To: /content/SpTransformer-Colab/model/weights/SpTransformer_pytorch.ckpt\n",
            "100% 120M/120M [00:03<00:00, 31.5MB/s]\n",
            "/content/SpTransformer-Colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 下载基因组文件"
      ],
      "metadata": {
        "id": "nCwW4feh-JL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1️⃣ 创建文件夹并进入\n",
        "!mkdir -p /content/SpTransformer-Colab/data/data_package\n",
        "%cd /content/SpTransformer-Colab/data/data_package\n",
        "\n",
        "# 2️⃣ 下载 hg38.fa.gz\n",
        "!wget -c https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz\n",
        "\n",
        "# 3️⃣ 解压并重命名为 hg38.fa\n",
        "!gunzip -c hg38.fa.gz > hg38.fa\n",
        "\n",
        "# 4️⃣ 下载 GENCODE v44 注释文件并重命名\n",
        "!wget -c https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_44/gencode.v44.annotation.gtf.gz -O hg38.annotation.gtf.gz\n",
        "\n",
        "# 5️⃣ 查看结果\n",
        "!ls -lh\n",
        "\n",
        "%cd /content/SpTransformer-Colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWwQGoeN3cMF",
        "outputId": "c2b40c2e-72c0-4f8b-fbc1-233ae7be3d8f",
        "collapsed": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SpTransformer-Colab/data/data_package\n",
            "--2025-11-12 02:11:49--  https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz\n",
            "Resolving hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)... 128.114.119.163\n",
            "Connecting to hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)|128.114.119.163|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 983659424 (938M) [application/x-gzip]\n",
            "Saving to: ‘hg38.fa.gz’\n",
            "\n",
            "hg38.fa.gz          100%[===================>] 938.09M  21.6MB/s    in 33s     \n",
            "\n",
            "2025-11-12 02:12:22 (28.3 MB/s) - ‘hg38.fa.gz’ saved [983659424/983659424]\n",
            "\n",
            "--2025-11-12 02:13:06--  https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_44/gencode.v44.annotation.gtf.gz\n",
            "Resolving ftp.ebi.ac.uk (ftp.ebi.ac.uk)... 193.62.193.165\n",
            "Connecting to ftp.ebi.ac.uk (ftp.ebi.ac.uk)|193.62.193.165|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49721965 (47M) [application/x-gzip]\n",
            "Saving to: ‘hg38.annotation.gtf.gz’\n",
            "\n",
            "hg38.annotation.gtf 100%[===================>]  47.42M  26.2MB/s    in 1.8s    \n",
            "\n",
            "2025-11-12 02:13:08 (26.2 MB/s) - ‘hg38.annotation.gtf.gz’ saved [49721965/49721965]\n",
            "\n",
            "total 4.1G\n",
            "-rw-r--r-- 1 root root  48M Jul 17  2023 hg38.annotation.gtf.gz\n",
            "-rw-r--r-- 1 root root 3.1G Nov 12 02:13 hg38.fa\n",
            "-rw-r--r-- 1 root root 939M Jan 16  2014 hg38.fa.gz\n",
            "/content/SpTransformer-Colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pyensembl install --reference-name hg38 --annotation-name gencode.v38 --gtf \"/content/SpTransformer-Colab/data/data_package/hg38.annotation.gtf.gz\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2TQbK-wsOlMz",
        "outputId": "88a5285f-d15e-400e-f61a-decaac2259e1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-12 02:13:11,948 - pyensembl.shell - INFO - Running 'install' for Genome(reference_name=hg38, annotation_name=gencode.v38, annotation_version=None, gtf_path_or_url=/content/SpTransformer-Colab/data/data_package/hg38.annotation.gtf.gz, transcript_fasta_paths_or_urls=, protein_fasta_paths_or_urls=)\n",
            "2025-11-12 02:13:11,948 - pyensembl.database - INFO - Creating database: /content/SpTransformer-Colab/data/data_package/hg38.annotation.gtf.db\n",
            "2025-11-12 02:13:11,949 - pyensembl.database - INFO - Reading GTF from /content/SpTransformer-Colab/data/data_package/hg38.annotation.gtf.gz\n",
            "2025-11-12 02:14:46,009 - pyensembl.database - INFO - Skipping database index for {ccds_id}\n",
            "2025-11-12 02:14:49,455 - datacache.database_helpers - INFO - Creating database /content/SpTransformer-Colab/data/data_package/hg38.annotation.gtf.db containing: start_codon, transcript, exon, CDS, gene, stop_codon\n",
            "2025-11-12 02:14:49,455 - datacache.database - INFO - Running sqlite query: \"CREATE TABLE start_codon (strand TEXT NOT NULL, start INT NOT NULL, transcript_support_level TEXT NOT NULL, source TEXT NOT NULL, exon_id TEXT NOT NULL, feature TEXT NOT NULL, protein_id TEXT NOT NULL, transcript_name TEXT NOT NULL, exon_number TEXT NOT NULL, gene_id TEXT NOT NULL, end INT NOT NULL, seqname TEXT NOT NULL, transcript_id TEXT NOT NULL, gene_name TEXT NOT NULL)\"\n",
            "2025-11-12 02:14:49,746 - datacache.database - INFO - Inserting 97962 rows into table start_codon\n",
            "2025-11-12 02:14:50,159 - datacache.database - INFO - Creating index on start_codon (seqname, start, end)\n",
            "2025-11-12 02:14:50,233 - datacache.database - INFO - Creating index on start_codon (gene_name)\n",
            "2025-11-12 02:14:50,299 - datacache.database - INFO - Creating index on start_codon (gene_id)\n",
            "2025-11-12 02:14:50,393 - datacache.database - INFO - Creating index on start_codon (transcript_id)\n",
            "2025-11-12 02:14:50,473 - datacache.database - INFO - Creating index on start_codon (transcript_name)\n",
            "2025-11-12 02:14:50,539 - datacache.database - INFO - Creating index on start_codon (exon_id)\n",
            "2025-11-12 02:14:50,610 - datacache.database - INFO - Creating index on start_codon (protein_id)\n",
            "2025-11-12 02:14:50,688 - datacache.database - INFO - Running sqlite query: \"CREATE TABLE transcript (strand TEXT NOT NULL, start INT NOT NULL, transcript_support_level TEXT NOT NULL, source TEXT NOT NULL, exon_id TEXT NOT NULL, feature TEXT NOT NULL, protein_id TEXT NOT NULL, transcript_name TEXT NOT NULL, exon_number TEXT NOT NULL, gene_id TEXT NOT NULL, end INT NOT NULL, seqname TEXT NOT NULL, transcript_id TEXT UNIQUE PRIMARY KEY NOT NULL, gene_name TEXT NOT NULL)\"\n",
            "2025-11-12 02:14:51,271 - datacache.database - INFO - Inserting 252835 rows into table transcript\n",
            "2025-11-12 02:14:53,669 - datacache.database - INFO - Creating index on transcript (seqname, start, end)\n",
            "2025-11-12 02:14:53,991 - datacache.database - INFO - Creating index on transcript (gene_name)\n",
            "2025-11-12 02:14:54,305 - datacache.database - INFO - Creating index on transcript (gene_id)\n",
            "2025-11-12 02:14:54,626 - datacache.database - INFO - Creating index on transcript (transcript_name)\n",
            "2025-11-12 02:14:54,883 - datacache.database - INFO - Creating index on transcript (exon_id)\n",
            "2025-11-12 02:14:54,994 - datacache.database - INFO - Creating index on transcript (protein_id)\n",
            "2025-11-12 02:14:55,162 - datacache.database - INFO - Running sqlite query: \"CREATE TABLE exon (strand TEXT NOT NULL, start INT NOT NULL, transcript_support_level TEXT NOT NULL, source TEXT NOT NULL, exon_id TEXT NOT NULL, feature TEXT NOT NULL, protein_id TEXT NOT NULL, transcript_name TEXT NOT NULL, exon_number TEXT NOT NULL, gene_id TEXT NOT NULL, end INT NOT NULL, seqname TEXT NOT NULL, transcript_id TEXT NOT NULL, gene_name TEXT NOT NULL)\"\n",
            "2025-11-12 02:14:58,796 - datacache.database - INFO - Inserting 1649476 rows into table exon\n",
            "2025-11-12 02:15:06,344 - datacache.database - INFO - Creating index on exon (seqname, start, end)\n",
            "2025-11-12 02:15:08,688 - datacache.database - INFO - Creating index on exon (gene_name)\n",
            "2025-11-12 02:15:09,947 - datacache.database - INFO - Creating index on exon (gene_id)\n",
            "2025-11-12 02:15:11,295 - datacache.database - INFO - Creating index on exon (transcript_id)\n",
            "2025-11-12 02:15:12,780 - datacache.database - INFO - Creating index on exon (transcript_name)\n",
            "2025-11-12 02:15:14,018 - datacache.database - INFO - Creating index on exon (exon_id)\n",
            "2025-11-12 02:15:15,656 - datacache.database - INFO - Creating index on exon (protein_id)\n",
            "2025-11-12 02:15:16,961 - datacache.database - INFO - Running sqlite query: \"CREATE TABLE CDS (strand TEXT NOT NULL, start INT NOT NULL, transcript_support_level TEXT NOT NULL, source TEXT NOT NULL, exon_id TEXT NOT NULL, feature TEXT NOT NULL, protein_id TEXT NOT NULL, transcript_name TEXT NOT NULL, exon_number TEXT NOT NULL, gene_id TEXT NOT NULL, end INT NOT NULL, seqname TEXT NOT NULL, transcript_id TEXT NOT NULL, gene_name TEXT NOT NULL)\"\n",
            "2025-11-12 02:15:19,795 - datacache.database - INFO - Inserting 885109 rows into table CDS\n",
            "2025-11-12 02:15:23,748 - datacache.database - INFO - Creating index on CDS (seqname, start, end)\n",
            "2025-11-12 02:15:24,640 - datacache.database - INFO - Creating index on CDS (gene_name)\n",
            "2025-11-12 02:15:25,216 - datacache.database - INFO - Creating index on CDS (gene_id)\n",
            "2025-11-12 02:15:25,864 - datacache.database - INFO - Creating index on CDS (transcript_id)\n",
            "2025-11-12 02:15:26,584 - datacache.database - INFO - Creating index on CDS (transcript_name)\n",
            "2025-11-12 02:15:27,214 - datacache.database - INFO - Creating index on CDS (exon_id)\n",
            "2025-11-12 02:15:28,055 - datacache.database - INFO - Creating index on CDS (protein_id)\n",
            "2025-11-12 02:15:28,820 - datacache.database - INFO - Running sqlite query: \"CREATE TABLE gene (strand TEXT NOT NULL, start INT NOT NULL, transcript_support_level TEXT NOT NULL, source TEXT NOT NULL, exon_id TEXT NOT NULL, feature TEXT NOT NULL, protein_id TEXT NOT NULL, transcript_name TEXT NOT NULL, exon_number TEXT NOT NULL, gene_id TEXT UNIQUE PRIMARY KEY NOT NULL, end INT NOT NULL, seqname TEXT NOT NULL, transcript_id TEXT NOT NULL, gene_name TEXT NOT NULL)\"\n",
            "2025-11-12 02:15:28,946 - datacache.database - INFO - Inserting 62700 rows into table gene\n",
            "2025-11-12 02:15:29,283 - datacache.database - INFO - Creating index on gene (seqname, start, end)\n",
            "2025-11-12 02:15:29,333 - datacache.database - INFO - Creating index on gene (gene_name)\n",
            "2025-11-12 02:15:29,381 - datacache.database - INFO - Creating index on gene (transcript_id)\n",
            "2025-11-12 02:15:29,404 - datacache.database - INFO - Creating index on gene (transcript_name)\n",
            "2025-11-12 02:15:29,426 - datacache.database - INFO - Creating index on gene (exon_id)\n",
            "2025-11-12 02:15:29,447 - datacache.database - INFO - Creating index on gene (protein_id)\n",
            "2025-11-12 02:15:29,468 - datacache.database - INFO - Running sqlite query: \"CREATE TABLE stop_codon (strand TEXT NOT NULL, start INT NOT NULL, transcript_support_level TEXT NOT NULL, source TEXT NOT NULL, exon_id TEXT NOT NULL, feature TEXT NOT NULL, protein_id TEXT NOT NULL, transcript_name TEXT NOT NULL, exon_number TEXT NOT NULL, gene_id TEXT NOT NULL, end INT NOT NULL, seqname TEXT NOT NULL, transcript_id TEXT NOT NULL, gene_name TEXT NOT NULL)\"\n",
            "2025-11-12 02:15:29,695 - datacache.database - INFO - Inserting 91835 rows into table stop_codon\n",
            "2025-11-12 02:15:30,072 - datacache.database - INFO - Creating index on stop_codon (seqname, start, end)\n",
            "2025-11-12 02:15:30,137 - datacache.database - INFO - Creating index on stop_codon (gene_name)\n",
            "2025-11-12 02:15:30,195 - datacache.database - INFO - Creating index on stop_codon (gene_id)\n",
            "2025-11-12 02:15:30,258 - datacache.database - INFO - Creating index on stop_codon (transcript_id)\n",
            "2025-11-12 02:15:30,351 - datacache.database - INFO - Creating index on stop_codon (transcript_name)\n",
            "2025-11-12 02:15:30,415 - datacache.database - INFO - Creating index on stop_codon (exon_id)\n",
            "2025-11-12 02:15:30,486 - datacache.database - INFO - Creating index on stop_codon (protein_id)\n",
            "2025-11-12 02:15:30,563 - datacache.database - INFO - Running sqlite query: \"CREATE TABLE _datacache_metadata (version INT)\"\n",
            "2025-11-12 02:15:30,564 - datacache.database - INFO - Running sqlite query: \"INSERT INTO _datacache_metadata VALUES (3)\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/SpTransformer-Colab\n",
        "!python /content/SpTransformer-Colab/sptransformer.py --input data/example/input38.vcf --output output_unc13a.tsv --reference hg38 --raw_score True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEkJzTZO3cOl",
        "outputId": "6d61a741-bf85-4718-86e1-9a1459a42514",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SpTransformer-Colab\n",
            "Warning: gencode grch37 gtf file not found, You can download from https://www.gencodegenes.org/human/release_19.html\n",
            "Please ignore this warning if you are using hg38\n",
            "hg19 fasta not found\n",
            "torch device:cpu\n",
            "Reading vcf file:data/example/input38.vcf\n",
            "1it [00:19, 19.18s/it]\n",
            "INFO:rpy2.rinterface_lib.embedded:Embedded R ended.\n",
            "INFO:rpy2.rinterface_lib.embedded:Embedded R already ended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== 新增：这三段工具函数，用于解析区间 & 取序列 ====\n",
        "import re\n",
        "from pyfaidx import Fasta\n",
        "\n",
        "def parse_region(region: str):\n",
        "    \"\"\"\n",
        "    支持：chr19:17642000:17643000:-  或  chr19:17642000-17643000:-  或无链符号默认 +\n",
        "    返回: chrom, start, end, strand（1-based, 闭区间）\n",
        "    \"\"\"\n",
        "    region = region.strip()\n",
        "    strand = '+'\n",
        "    if region.endswith(':+') or region.endswith(':-'):\n",
        "        region, strand = region.rsplit(':', 1)\n",
        "    m = re.match(r'^([^:]+):(\\d+)[-:](\\d+)$', region)\n",
        "    if not m:\n",
        "        raise ValueError(f\"无法解析区域: {region}\")\n",
        "    chrom, s, e = m.group(1), int(m.group(2)), int(m.group(3))\n",
        "    if s > e:\n",
        "        s, e = e, s\n",
        "    return chrom, s, e, strand\n",
        "\n",
        "def revcomp(seq: str) -> str:\n",
        "    tbl = str.maketrans(\"ACGTNacgtn\", \"TGCANtgcan\")\n",
        "    return seq.translate(tbl)[::-1]\n",
        "\n",
        "def fetch_seq_with_flanks(fasta: Fasta, chrom: str, start: int, end: int, strand: str = '+', flank: int = 4000) -> str:\n",
        "    # pyfaidx 使用 1-based，且 end 为包含\n",
        "    if chrom not in fasta:\n",
        "        raise KeyError(f\"FASTA 中不存在染色体: {chrom}\")\n",
        "    chrom_len = len(fasta[chrom])\n",
        "    s = max(1, start - flank)\n",
        "    e = min(chrom_len, end + flank)\n",
        "    seq = fasta.get_seq(chrom, s, e).seq.upper()\n",
        "    if strand == '-':\n",
        "        seq = revcomp(seq)\n",
        "    return seq\n",
        "\n",
        "fasta_path = \"/content/SpTransformer-Colab/data/data_package/hg38.fa\"     # 改成你的FASTA路径\n",
        "region_str = \"chr19:17642000:17642944:-\"  # 改成你的输入\n",
        "\n",
        "fa = Fasta(fasta_path, sequence_always_upper=True)\n",
        "chrom, start, end, strand = parse_region(region_str)\n",
        "seq = fetch_seq_with_flanks(fa, chrom, start, end, strand, flank=4000)\n",
        "print(seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvmHn4iELAkW",
        "outputId": "4bd419a1-eaa2-4e27-b230-bab5e22413b9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AAGGAGTCCTGAAGGAGATGCCGTTGAGCAGACAATGCTGTGGGCAAGGGGGTCAGCCCATCCTGGGGCCACTGGGGACAATGTCGAGCATGCAGCTCAGTGTGGCCCCACTTAGGGGCGAGGATACTGGCTTTTCTCCACACCCAGCCTCATGTGGGTTTCCCCATAAACAGACCTGAGGATGAGGATTTCAGGTTATGTGGGTTATCCAGGAAGTGACCCCAGGACGGAGCTGGGGTGGTAAGTCAGGGAGGGAAGGAACCCTGCAGGGGGCACCAACGAGCAGGAGATCTCGGGGGGCAATGGGTTCTTGTAAGTGTCTGACCTCAGGGAGTTCACACCTGAGAGAGGTCCTACCCATGCGCAAGGCAGCTGGGGCACCTTCCCATCCTTCATGGTTTGGGGACTCCTTCCCAGCACTTTGGGAGGCTGAGGCTGAGGCAGGCGGATCACCTGAGGTCAGGAATTCGAGACCGACCTGGCCAACATGGTGAAACCCCATCTCTACTAAAAATGCAAAACGATTGGCCGGATGGGGTGGCACGTGCGGGTAATCCCAGCTACTTGGGAGGCTGAGGCAGGAGAATTGCTTGAACCCGGGAGGCGGAGGTTGCACTCCAGCCTGGGTGACGAGCAAAACTCTGTCTCAAAAACAAACAAACAAACAAACAAACACACAAAAAACCTCTCTGGCAAGCCCAGCGTGCCCTGCCATTGCTCTCCAGCCATGCTGCAGGTGTCCCAATTATCAGCCTGCAGCGTGTGGCAGTGACTGTCCCCAGCATGCCTCGCTTCTTGAGTGCACACCTGTGTATGCCCTCTGTGTCTTCCAGTGGTCTGCGCCCAGGGCTTGCAGGCAAAGGACAAGACAGGATCCAGTGACCCCTATGTCACCGTCCAGGTCGGGAAGACCAAGAAACGGACAAAAACCATCTATGGGAACCTCAACCCGGTGTGGGAGGAGAATTTCCACTTGTAAGTGCCTGGCTGGGTCCCTGGCCCCATGTGGGGCATCCTGCTGGGGCAGCCAAAAGAGGGCTCCAAGGACAGGACTCACACTGGCTGCCTGACCCCTGCCTCTGCCTCCTCCTCCCGCCACAGTGAATGTCACAATTCCTCCGACCGCATCAAGGTGCGCGTCTGGGACGAGGATGACGACATCAAATCCCGCGTGAAACAGAGGTTCAAGAGGGAATCTGACGATTTCCTGGGGCAGACGATCATTGAGGTGCGGACGCTCAGCGGCGAGATGGACGTGTGGTACAACCTGGGTGAGAGAAGCTGGGTTCTGAAGCGGGTGGGGACGGGTCCCAGGGATCCAGCCAGAGCATGGAGCCCACGAAGAGCAGAGAGATGTGTTCTCAGGAGGAGTTTGGTCGAGGAGCATAATCTGATGGGGGAGGCAGGGTCTAGGAGCCCAGTTTGATGGGAGCAGGAAGCACCCAGGCCAGGAGGGTGAGCAGAGCCCAGGAACCTCTTAGTTCAGCTTAGGAGGGAGGGTGGGGACAGAATCTCCATGTTCTAGTCTAATGGGGGAGGCAAGAAGCAAGAACTGGGAATCCTAGTCTGAGGGGAGAGACAGAGACCTAGGAACTAAATCTAAGAAAGAAGATTGAGCTTTAAGAATCCAGGCTGGGGCCAGGTATGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAAGCTGAGGCAGGCAGATCACATGAGGTCAGGAGTTCGAGACCAGCCTGGCTAACATGGTGAAACCCCGTCTCCACTAAAAATACAAAAATTAGCCAGGCGTGGTGGTGGGTGCCTGTAGTCCCAGCTACTTGGGAGGCTGAGGCAGGAGAATCGCTTGAACCCAGGAAGCGGAGGTTGCAGTGAGCTGAGACTGCGCCACTGCACTCCAGCCTAGGCAACGAGAGCAAAACTCCCACTCAAAAAAAAAAAAAAAAGAATCCAGGCTGGGGGCGCCGGGCAGTGGCTCACATCTGTAATTAATCCTATCACTATGGGAGGCTGAGGCAGGCCAATCACTTGAGTCCAGGAGTTCAAGACCAGCCTGGGCAACATAGTGAAACCCCATCTCTATAAAAGATACAAAAATTAGCTAGGCAGGGTGACACTCACCTGTGGTCCCACCTACTCTGGAGGCTAAGGTGGGAGGATCCCCTGAGCCTGAGAGGTAAAGGCTGCAGTGAGCTGTGATCACACTGCTGCACTCCAGCCCAGGGAACAGAGTGAGACCCTTTCTCAAAAAACAAATATGGCCGGGTGCAGTGTCTCACGCCTATAATCCCAACAGTTTGGGACGGCTGAGGCAGGCAGATCACTTGAGGTCAGGAGTTTGAGACCAGATTGTCCAACATGGCGAGATCAAGCCCCTGCACTCCAGCCTGGGCAACAAAGGAAGACTCCGTCTCAAAAAAAAAAAAAAAAAACAAAAGAAAAAGAAAAAAAAAATGGAATCCAGGCTGGGCATGGTGGCTCCCACCTGTTATCCCAACATATTGGTTGGGTGGCTGAGCTGGGAGGGTCACTTGAGCCCAGGAGTTCGAGACCAGCCTGGGCAACATAACAAGGCCTTTGTCTCCATTAAAAAAAAAAAAATAGCTGGGTGTGGTGATGCGTGCCTGTAGTCCCAGCCACTTGGGAGGCTGAGGTGGAAGCATCATTTGTACCTGGGAGGTTGAAGCTGCAGTGAGCTATGATCATGCCACTGCACTCCAGCCTGGGCGATAGAGCAAGACTCTGTGTCCCCCCGACCCCCCACCACAAGAAAAGAATCCAGTCTAAAGAGGGAGGTATTGTTTGGGAATCCTAATCTGAGATGGCTGCTACAGATCAAAGAACCCTGTGTAAGGAAGTTGAGTAGAATCTGGGGAGTCCAATCTAATGGAGGAAGCAGGGTGTATGAGCCTAATCTGAGGGGGTAGAAAGGACCCAGCCTGAGAGAGGTGAGCAGAGCCCGGAAACCTCTTAGATTGGAGGACATCTAGATATCCCATTCTGATGGGGGAGGTGGGAGACAAGACCAGGGGGTCCTAGTCTGAGGAGAGAGGCACAGACCCAGGAACAGTGTCTAAGATGTGTAGTCTCCGGGGAGCATGATCTGATGGGGGAGGCAGGGCCTGGGAGCTCAGACTGGGAAAGAAGTGGGGCCTAGGGCTGCTAGTCTAAGGAGGGAGGCACATAGCCAGGAACTTAATCTGAGTGAAGAAGCAAGGTCTGGGATCCTTGTTTGAAGGAAGAGACAGGGCTTAAGGAATTCTAGCCTAAACAGGGAGACTCAAGCCTAGGGAGCCAATCAGAAGAGAGACACCAAAGCCTTAGTTTCCGGAAGTCTGGGAGGACTACAGAATCGTGTATCTATTAAAAATTGCCTTGGGAGGCCGAGGCGGGCGGATCACCTGAGGTCAGGAGTTCGAGACCAGCCTGGCCAACATGGTGAAACCTCGTCTCTACTAAAAATAAAAAATTAGGTGGGTGTGATGGCACATGCCTGTAATCCCAGCTACTCGGGAGGCTGAGGCAAGACAATTGCTTGAACTCAGGAGGTGGAGATTGCAGTGAGCCAAGATTGCGCCACCGCACTCTAACCTGGACCACAGATCTCAAAAAAAAATAAAATAAAAAAAAATTTGCCCATGGCTGGCCGGGCGCGGTGACTCACGCCTGTAATTCCAGCACTTTGGGAGGCTGAGGTAGGTGGATCACCTGAGGTAAGGAGTTCGAGACCAGCCTGGCCAACATGGTGAAACCCCGTCTCTACTAAAAGTATAAAAATTAGCTGGGCACGGTGGCAGGCACCTGTAATTCCAGCTAGTTGGGAGGCTGAGACAGGAGAATCGCTTGAACCCAGGAGGTGGAGGTTGCAGTGAGCTGAGATCGTGCCACTGCACTCCAGCCTGGGTGACAAGAGCAAGACTCCCTCTTAAAAAAAAAAAAATTGCCCACTGCTATAGTGGGAAGTTCTGACACTGTCTTCTTTTTCTGCCCTGCAGACAAGCGAACTGACAAATCTGCCGTGTCGGGTGCCATCCGGCTCCACATCAGTGTGGAGATCAAAGGCGAGGAGAAGGTGGCCCCGTACCATGTCCAGTACACCTGTCTGCATGAGGTGAGGGTCATTGCTCGGCCCCTCCCATGCCACTTCCACTCACCATTCCTGCCTGCCCAGCTCTTCCTCTTTCTGGCCACACCATCCACACTCTCCTGGCCCTCTGAGACTGCCCGCCATGCCATTCCCTTTACCTGGAAAACTCCTCCCTATCCATCAAAGTCCAGATTCAGGGTCACCTCCTCTGGGAAGCCCACCTTGGCCTCCAGGTTGACTCTCACTACTCATCATCAGGTTCTTCCTTCTATTCCAGCCCTAACCACTCAGGATTGGGCCGTTTGTGTCTGGGTATGTCTCTTCCAGCTGCCTGGGTTTCCTGGAAAGAACTCTTATCCCCAGGAACTAGTTTGTTGAATAAATGCTGGTGAATGAATGAATGATTGAACAGATGAATGAGTGATGAGTAGATAAAAGGATGGATGGAGAGATGGGTGAGTACATGGATGGATAGATGGATGAGTTGGTGGGTAGATTCGTGGCTAGATGGATGATGGATGGATGGACAGATGGATGGATATATGATTGAACTATTGAAAGTATAGATGTATGGATGGGTGAATTTGGGGGTAATTGTTAGATGATGGATGAGTATAGATGAATGATGGATGGATAACTTGATGAGTGGATAGATAGATTGCTGGATAGATGATTGACTGGGTGGATAGATGAAATGTTGGATGAGCAGATTAAGTTGTATTGGATGGGATGGATGGAAGTGTGGTTGAGTTATTAGAAGGAAGATTGAGTAGATAGGTGAATTTGTTGATAGTCAGATGGGTAGATAGGTAGATGGATGGATGGATGGATGGATGTATAGGCAGATGGACAAATGGATGAATGGGTGGGTGGATGAATGGAAGGATGTGTGGTTGAACTATTGCAAGTATTGATAATTGGGTTCATAATTTCTGAATATTTAGATGGATGGTTGTGAGTGGCTGGTGGACAGACGAAAAATGGATGGTTGGATAAATTGATGGGTGGATGGATGGTTGGTTGTATGAAAGAATGAATGATTGGGTAGGTGGATTAAGTTGCGGATCAATGTATGGGATGGATGAATGGATGGATGGATGGATGTGTGGTTGAATTACTGAAAGGTTGGAAGAGTGGATGGGTGAAATTTGGGGTAGTTAGATGGGTGGGTGTGTGGATGGATAAAAGAGTAGATGAATGAATTAATGAATAAACAGGCAGATGGATGATGTAAGCTGCCCCAGACCCTGGGACCTCTGACCCCCGGCGACCCCTTGCACTCTCCATGACACTTTCTCTCCCATGGTGGCAGAACCTGTTCCACTTCGTGACCGACGTGCAGAACAATGGGGTCGTGAAGATCCCAGATGCCAAGGGTGACGATGCCTGGAAGGTTTACTACGATGAGACAGCCCAGGAGATTGTGGACGAGTTTGCCATGCGCTACGGCGTCGAGTCCATCTACCAAGCCATGACGTGAGACTGCAGGCTGGGGTGCAGGAAACAAGAGGGAGGTCACCAAGTGGGCACTGGCAGGTCTGGGGTGGGAGGGATTCTCAGGGGGAAGACCCAGAGAGGAAGTGGGCGTGGTGGTGGTGGGTTCCGTAATTCCCCTGGAGATCAGGAGAGCGCTGTGATTGACACCTGGAGTGACATGGAAGAGAGGGAAGACTTAGAAGCAGAGATAGAGGCTGGGCACAGTGGCTCAAGCCTGTAATCCCAGCATTTTAGGAGGCTGAGGTGGGCGGATCACTCCAGGTCCAGGAGTACAAGACCAGCCTGGCCAACATGGTGAAACCCCATCTCTACTAAAAATACAAAAGTTATCCAGGTGTGGTGGCTTGGGCCTGTAATCCCAGCTACTCGGGAAGTTAGGGTGGGAGAATTGCTTGAACCTGGGGGGCAGGGGTTGCAGTGAGCCGAGATTGCGCCACTAAACTCCAGCCTGGGTGACAGAGTGAGACTCCATCTCAAAAAAAAAAAAAAAAGAAAGAAAGAAAAAAAGAAGCAGAATTAGAGCAACTCAAATGGATATAAAGATGGAGGGGAGAGGAGATGCGGAGACCCAAAGGACAGAATCAGGCAGGGGATGGTTTAGGAGGTGACAGAGACCCACTCACAGATGCTATCTTGGAGGCATTCTAGGGGGGATCTTGGTCCATCCTGGCTGGACCCCTGGCCTAGTGCCTCCTGCTCCCTCTCTCCAGCCACTTTGCCTGCCTCTCCTCCAAGTATATGTGCCCAGGGGTGCCTGCCGTCATGAGCACCCTGCTCGCCAACATCAATGCCTACTACGCACACACCACCGCCTCCACCAACGTGTCTGCCTCCGACCGCTTCGCCGCCTCCAACTTTGGGGTCAGTCCTGGGGACTGGGATTGGAGAATTAGGGAGAGCCCAACTTTATGCCGGTCAGATCTGATGTGACTTCTGGGTCCCCAGTCTAGACCTGATTGCTGTGTGACTTTCCACCAGTCACTTCCCGTCTCTGAGCCTCCATTTATTCCTCTGTAGAATGCTATAGAATGGAGGTCGGGCGCAGTGGCTCATGCCTGTAATCCCAGCACTTTGGGAGGCCGAGGCTGGAGAATCACTTGAGGCCAGGAGTTCGAGACCAGCCTGGCCAACACGGTGAAAACCCGTCTCTTCTAAAAATCCAAAAGAAAATTAGCTGGGTGTGGTGGCCTGTGCCTGTAGTCCCAGCCACTTGGGAGGCTGAGGCAGGAGAATTGCTTGAGCCTAGGAGTCGGAGGTTGCAGTGAGCTGAGACTGCGCCACTACACTCCAGCCTGGGCAACAGAGCAAGACTCTGTCTCAAAACAAAAAAAAAAATGCCATAGAATGGAAATGGACATTATGAGGGTGGTGGATGAGGTATACTTACTGTACAGTAGGCGCTCAGCCACTATGGCGGCCATGTCCTGCCTCCATCCATCCTCCCTCCTCCCCTTCCTCCTCAGAAAGAGCGCTTCGTGAAACTCCTGGACCAGCTGCATAACTCCCTGCGGATTGACCTCTCCATGTACCGGGTAGGAAGTGTGTGCATGAGAATTTGCTCACCCCACGCACATGTGTGTGCCTGGAGGGGAAAGCTACCAGCAGGTGTGTGCATGGGAGGACCCATCTTCGCATGTACGATGTGTTCCTCCAGCATGTGTGCACCTGCATGGGCACTACCTGCCGTAATGTGCTTGGTGCATCCAAGCAGATCCCCAGTTGCTTCGAGGTGCTCTAATCAACCCCCAGCCTGAAACCGGGGAGCCTTTGTATCCCCCTGAAAAGCAGTCTCCCATCCTCCCCACGCCTTCTTCCATAACCCCACATCTCTTCCTGCTCCCAACAGAATAACTTCCCAGCCAGCAGCCCGGAGAGACTCCAGGACCTCAAATCCACTGTGGACCTTCTCACCAGCATCACCTTCTTTCGGATGAAGGTAGGAAAGGATCCAGTTGCCTTTGCTCTCCAAGGAGGGTTCTCTAGGATCCCCAGCTCCCAGGACAAGTGACATTCCTCCTGGAGAGTGGCAGCCTTTCTCAGTAACCTTTTCCTTTCATACCACTTCATTTCCTTAAACCCAAAATGACTCGCAGTCACTTCCTGGGGACCTCCTGTCACAGCTGTGGCCGCCTATGCCTCTCTCCCTCCCTTCAGGTACAAGAACTCCAGAGCCCGCCCCGAGCCAGCCAGGTGGTAAAGGACTGTGTGAAAGCCTGCCTTAATTCTACCTACGAGTACATCTTCAATAACTGCCATGAACTGTACAGCCGGGAGTACCAGACAGACCCGGTGAGACTCCAGATGGGTCAGAAGGGAACAGTGATGCCAACTAGACACAGGCTTCAGTCCCAGCCCTGCCCCTTCCCGAGGGATTTAACTCTTCTGAACCTCAGTATCTTCTTCTATAAAATGGGGTCATTAACCCACATCTCAGGATTAGGGAGAAGAGTTCATGAGCTGTAAGTTTAGATAAAATATAGTCGGCACTCAGTACATTTGGTTGCGTAGTTGAGTTTGGCATAAAAAAAAATTTTTTTTTTTTGAGATAAAGTTTCACTCTTGCTTCCCAGGCTGGAGTGCAGTGGTGTGATCTCAGCTCACTGCAACCTCTGCCTCCCAGGTTTAAATGATTCTCCTGCCTCAGACTCCCGAGTAGCTGGGATTACAGGTGCCCACCACCACACCTAGTTAATTTTTTGTATTTTTAGTAAAAACGGGGTTTCACCATGTTGGCCAGGCTGGTCTCGAACTCCTTGACCTCAGGTGATCCACCTGCCTCGGCCTCCCAAAGTACTGAGATTATAGGCGTGAGCCACCACTCCCAGCCTGGCATAAAAATTTATGTCTGGCATACAGTCACTGTTCAGTAAATGTTGAGTTGAATTGAATTTATTTATTTATTTTGAGATGGGGTCTTGCTCTGTTGCCCAGGCTGGAGTGCAGTGATGCAATCATGGCTCACTGCAGCCTCGACCTCCCAGGCTCAAGTGATCCTCCCACCTCAGCCTCCCAAGTAGCTGGGACTATAGGCACGCACCACCATGACAGGCTAGTTTTTGTATTTTTGTGGAGATGGCATCTCACTATGTTGCCCAGGCTGATCTCCTGGGCTCAAGCGATCCTCCTGCCTCAGCCTCCCAAAGTGCTGGGATTACAGGCATGAGCCACCACCTGTAAGGAGCTTATAGCCTATTATGAGGGAAAGATGTACAAACTGGAAATTTACAAACAGGGATGGTTAGTATTGAGATAGTGGGATCTCAGGAGGCTGTGGGAGCTGGAGGCAGCCCCTACCCAGGTTCTGATAGGATATAACACATAAGCTGTGTTCAGTTCAATTTGATTTCATTCTGTTCCTTTACATTCAGTTGA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall numpy==1.26.4\n",
        "!pip install --force-reinstall pandas pyfaidx"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1nSjdgolNBZr",
        "outputId": "a9a99d9c-4ade-422d-fb8e-796065c79001"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "bigframes 2.28.0 requires pyarrow>=15.0.2, but you have pyarrow 14.0.2 which is incompatible.\n",
            "datasets 4.0.0 requires pyarrow>=15.0.0, but you have pyarrow 14.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "2249c80c18fa4f8fb89d123d574e9030"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas\n",
            "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/91.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyfaidx\n",
            "  Using cached pyfaidx-0.9.0.3-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting numpy>=1.26.0 (from pandas)\n",
            "  Downloading numpy-2.3.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil>=2.8.2 (from pandas)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting packaging (from pyfaidx)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pyfaidx-0.9.0.3-py3-none-any.whl (29 kB)\n",
            "Downloading numpy-2.3.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pytz, tzdata, six, packaging, numpy, python-dateutil, pyfaidx, pandas\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.2\n",
            "    Uninstalling pytz-2025.2:\n",
            "      Successfully uninstalled pytz-2025.2\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.2\n",
            "    Uninstalling tzdata-2025.2:\n",
            "      Successfully uninstalled tzdata-2025.2\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0.post0\n",
            "    Uninstalling python-dateutil-2.9.0.post0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "  Attempting uninstall: pyfaidx\n",
            "    Found existing installation: pyfaidx 0.9.0.3\n",
            "    Uninstalling pyfaidx-0.9.0.3:\n",
            "      Successfully uninstalled pyfaidx-0.9.0.3\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.4 which is incompatible.\n",
            "bigframes 2.28.0 requires pyarrow>=15.0.2, but you have pyarrow 14.0.2 which is incompatible.\n",
            "datasets 4.0.0 requires pyarrow>=15.0.0, but you have pyarrow 14.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.3.4 packaging-25.0 pandas-2.3.3 pyfaidx-0.9.0.3 python-dateutil-2.9.0.post0 pytz-2025.2 six-1.17.0 tzdata-2025.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "numpy",
                  "packaging",
                  "pandas",
                  "pyfaidx",
                  "pytz",
                  "six"
                ]
              },
              "id": "64914c79e25c4de6a245b42118342365"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/SpTransformer-Colab\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pyfaidx import Fasta\n",
        "import argparse\n",
        "import vcf as pyvcf\n",
        "from pyensembl import Genome\n",
        "import tqdm\n",
        "import os\n",
        "from sptransformer import Annotator\n",
        "import torch\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    annotator = Annotator()\n",
        "    gtf = annotator.gtf\n",
        "\n",
        "    tis_names = ['Adipose Tissue', 'Blood', 'Blood Vessel', 'Brain', 'Colon', 'Heart', 'Kidney',\n",
        "                 'Liver', 'Lung', 'Muscle', 'Nerve', 'Small Intestine', 'Skin', 'Spleen', 'Stomach']\n",
        "\n",
        "    input_seq = annotator.model.one_hot_encode(seq)\n",
        "    input_seq = torch.tensor(input_seq).to(annotator.model.device)\n",
        "    print(input_seq.shape)\n",
        "    # the function step() accepts encoded sequence, (Batch, 4, Length),\n",
        "    # thus, the input_seq should have shape (1, 4, Length)\n",
        "    input_seq = input_seq.unsqueeze(0).float().transpose(1, 2)\n",
        "    output = annotator.model.step(input_seq)\n",
        "    print(output.shape)"
      ],
      "metadata": {
        "id": "7iel0Qi6Cqb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2da67e15-54a3-4149-97ff-7a6f0e1e99d5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SpTransformer-Colab\n",
            "Warning: gencode grch37 gtf file not found, You can download from https://www.gencodegenes.org/human/release_19.html\n",
            "Please ignore this warning if you are using hg38\n",
            "hg19 fasta not found\n",
            "torch device:cpu\n",
            "torch.Size([8945, 4])\n",
            "torch.Size([1, 18, 945])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the tensor and remove the batch dimension\n",
        "reshaped_output = output.squeeze(0).transpose(0, 1)\n",
        "\n",
        "# Convert the tensor to a pandas DataFrame\n",
        "output_df = pd.DataFrame(reshaped_output.detach().numpy())\n",
        "\n",
        "# Save the DataFrame to a TSV file\n",
        "output_df.to_csv('output_reshaped.tsv', sep='\\t', index=False)\n",
        "\n",
        "print(\"Reshaped output saved to output_reshaped.tsv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zru_WqEcNugU",
        "outputId": "5aa5ecd9-c197-40bf-95b4-8633be015b87"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reshaped output saved to output_reshaped.tsv\n"
          ]
        }
      ]
    }
  ]
}